{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf api setup\n",
    "import time\n",
    "import asyncio\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "from sfapi_client         import Client, AsyncClient\n",
    "from sfapi_client.compute import Machine\n",
    "from sfapi_client.jobs    import JobState\n",
    "\n",
    "from sfapi_connector import KeyManager, OsSFAPI, OsWrapper, LOGGER\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import webbrowser\n",
    "from io import BytesIO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job state is: JobState.PENDING (<enum 'JobState'>)\n",
      "error: ls: cannot access '/global/homes/s/sanjeevc/sfapi_test/sfapi-demo-33084637.out': No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sf api send jobscript\n",
    "\n",
    "\n",
    "\n",
    "target = \"./sfapi_test\"\n",
    "# Variables\n",
    "env_name=\"sfapi_dask_env\"\n",
    "requirements_file=\"./sfapi_test/requirements.txt\"\n",
    "\n",
    "job_script = f\"\"\"#!/bin/bash\n",
    "#SBATCH -q debug\n",
    "#SBATCH -A m669\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 5              # Number of tasks (64 tasks, 32 per node)\n",
    "#SBATCH -C cpu\n",
    "#SBATCH -t 00:30:00\n",
    "#SBATCH -J sfapi-demo\n",
    "#SBATCH --exclusive\n",
    "#SBATCH --output=./sfapi_test/sfapi-demo-%j.out\n",
    "#SBATCH --error=./sfapi_test/sfapi-demo-%j.error\n",
    "\n",
    "# Print each command for debugging\n",
    "set -x\n",
    "\n",
    "\n",
    "# Load necessary modules\n",
    "module load conda\n",
    "#module load python dask\n",
    "\n",
    "# Ensure Conda is initialized\n",
    "source $(conda info --base)/etc/profile.d/conda.sh\n",
    "\n",
    "#test\n",
    "echo \"requirements.txt are at {requirements_file}\"\n",
    "\n",
    "# Check if the Conda environment exists; create or update if necessary\n",
    "if ! conda info --envs | grep -q \"^{env_name} \"; then\n",
    "    echo \"Creating Conda environment: {env_name}\"\n",
    "    conda create -y -n \"{env_name}\" python=3.9\n",
    "fi\n",
    "\n",
    "echo \"Activating Conda environment: {env_name}\"\n",
    "conda activate \"{env_name}\"\n",
    "\n",
    "if [ -f \"{requirements_file}\" ]; then\n",
    "    echo \"Installing dependencies from {requirements_file}\"\n",
    "    pip install -r \"{requirements_file}\"\n",
    "else\n",
    "    echo \"No requirements.txt found at {requirements_file}. ERROR: Skipping dependency installation.\"\n",
    "fi\n",
    "sleep 5\n",
    "\n",
    "\n",
    "# Start Dask Scheduler\n",
    "echo \"Starting scheduler...\"\n",
    "scheduler_file=$SCRATCH/scheduler_file.json\n",
    "rm -f $scheduler_file\n",
    "\n",
    "DASK_DISTRIBUTED__COMM__TIMEOUTS__CONNECT=3600s \\\n",
    "DASK_DISTRIBUTED__COMM__TIMEOUTS__TCP=3600s \\\n",
    "dask-scheduler \\\n",
    "    --interface hsn0 \\\n",
    "    --scheduler-file $scheduler_file &\n",
    "\n",
    "dask_pid=$!\n",
    "\n",
    "# Wait for the scheduler to start\n",
    "sleep 5\n",
    "until [ -f $scheduler_file ]; do\n",
    "    echo \"Waiting for scheduler to start...\"\n",
    "    sleep 5\n",
    "done\n",
    "echo \"Scheduler started\"\n",
    "\n",
    "# Start Dask Workers\n",
    "echo \"Starting workers...\"\n",
    "DASK_DISTRIBUTED__COMM__TIMEOUTS__CONNECT=3600s \\\n",
    "DASK_DISTRIBUTED__COMM__TIMEOUTS__TCP=3600s \\\n",
    "srun dask worker \\\n",
    "    --scheduler-file $scheduler_file \\\n",
    "    --interface hsn0 \\\n",
    "    --nworkers 1 > $SCRATCH/worker_log.out 2>&1 &\n",
    "\n",
    "echo \"Workers started. Check $SCRATCH/worker_log.out for details.\"\n",
    "\n",
    "# Wait a bit to ensure workers are started\n",
    "echo \"Sleeping...\"\n",
    "sleep 10\n",
    "\n",
    "# Check number of workers\n",
    "echo \"Verifying number of Dask workers...\"\n",
    "python -c \"\n",
    "from dask.distributed import Client\n",
    "client = Client(scheduler_file='$scheduler_file')\n",
    "print('Number of workers:', len(client.scheduler_info()['workers']))\n",
    "\"\n",
    "\n",
    "# Print hostname\n",
    "echo \"hostname: $(hostname -f)\"\n",
    "\n",
    "# Wait for client connection\n",
    "echo \"waiting for client connection...\"\n",
    "wait\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "km = KeyManager()\n",
    "\n",
    "with Client(key=km.key) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "\n",
    "\n",
    "\n",
    "    [path] = perlmutter.ls('/global/homes/s/sanjeevc/sfapi_test/', directory=True)\n",
    "    \n",
    "\n",
    "    # Read the file into memory as bytes\n",
    "    with open('./requirements.txt', 'rb') as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # Wrap the content in BytesIO\n",
    "    file_requirements = BytesIO(file_content)\n",
    "    file_requirements.filename = 'requirements.txt'  # Add the required filename attribute\n",
    "\n",
    "    path.upload(file_requirements)\n",
    "    print(f\"Uploaded requirements.txt to {path}\")\n",
    "    \n",
    "\n",
    "    job = perlmutter.submit_job(job_script)\n",
    "    job_global = job\n",
    "    print(f\"Submitted_job: {job.jobid}\")\n",
    "    job_id = job.jobid\n",
    "\n",
    "    while True:\n",
    "        job.update()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        print(f\"The job state is: {job.state} ({type(job.state)})\")\n",
    "        if job.state not in [JobState.PENDING, JobState.RUNNING, JobState.COMPLETING]:\n",
    "            if job.state == JobState.FAILED:\n",
    "                print(\"Job failed\")\n",
    "            elif job.state == JobState.COMPLETED:\n",
    "                print(\"Job completed\")\n",
    "                \n",
    "            elif job.state == JobState.TIMEOUT:\n",
    "                print(\"Job timeout\")\n",
    "                  \n",
    "            break\n",
    "        try: \n",
    "            output_file = perlmutter.ls(f\"/global/homes/s/sanjeevc/sfapi_test/sfapi-demo-{job_id}.out\") #todo change to relative paths\n",
    "            output_file = output_file[0]\n",
    "            with output_file.open(\"r\") as f:\n",
    "                file_content = f.read()\n",
    "                print(file_content)\n",
    "\n",
    "            # Parsing the hostname using a regex pattern #todo remove hostname search as hostname is not used\n",
    "            hostname_match = re.search(r\"hostname: (.+)\", file_content)\n",
    "            if hostname_match:\n",
    "                hostname = hostname_match.group(1)\n",
    "                print(f\"Hostname parsed: {hostname}\")\n",
    "                print(f\"---------------------------------\")\n",
    "                #find the dask ip for the ssh tunnel. This reads it from the scheduler file that dask makes\n",
    "                print(f\"Searching for Dask IP address...\")\n",
    "                output_file = perlmutter.ls(f\"/pscratch/sd/s/sanjeevc/scheduler_file.json\")\n",
    "                output_file = output_file[0]\n",
    "                with output_file.open(\"r\") as f:\n",
    "                    file_content = f.read()\n",
    "                    print(file_content)\n",
    "                \n",
    "                                # Parse the JSON content to extract the Dask IP\n",
    "                scheduler_info = json.loads(file_content)\n",
    "                dask_address = scheduler_info.get(\"address\", \"\")\n",
    "                daskip = re.search(r\"tcp://([\\d.]+):\", dask_address)\n",
    "\n",
    "                # Extract and print the IP address\n",
    "                if daskip:\n",
    "                    daskip = daskip.group(1)\n",
    "                    print(f\"Dask IP address: {daskip}\")\n",
    "                    \n",
    "                    \n",
    "                    # Open the SSH tunnel to perlmutter\n",
    "                    # Example usage\n",
    "                    command = [\n",
    "                        \"ssh\",\n",
    "                        \"-o\", \"ServerAliveInterval=30\", \n",
    "                        \"-l\", \"sanjeevc\",\n",
    "                        \"-i\", \"~/.ssh/nersc\",\n",
    "                        \"-L\", f\"8786:{daskip}:8786\",\n",
    "                        \"-L\", f\"8787:{daskip}:8787\",\n",
    "                        \"sanjeevc@perlmutter.nersc.gov\"\n",
    "                    ]\n",
    "                    subprocess.Popen(command)\n",
    "                    time.sleep(3)\n",
    "                    print(\"SSH tunnel opened\")\n",
    "                    webbrowser.open('http://localhost:8787/status')\n",
    "\n",
    "                   \n",
    "                   \n",
    "                   \n",
    "                   \n",
    "                    #keep tunnel open till user wants to close it and cancel the job\n",
    "                    input(\"Cancel job?\")\n",
    "                    job.cancel()\n",
    "                    print(\"Job cancelled\")\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    print(\"Dask IP address not found.\")\n",
    "                \n",
    "                \n",
    "                \n",
    "                break\n",
    "            else:\n",
    "                print(\"Hostname not found in the file.\")\n",
    "        except Exception as e:\n",
    "            print(f\"error: {e}\")\n",
    "        time.sleep(10)\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nersc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
